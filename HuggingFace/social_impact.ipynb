{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We're going to use the `wikitext` (https://huggingface.co/datasets/wikitext) dataset with the `distilbert-base-cased` (https://huggingface.co/distilbert-base-cased) model checkpoint. \n","\n","Start by loading the `wikitext-2-raw-v1` version of that dataset, and take the 11th example (index 10) of the train split.\n","We'll tokenize this using the appropriate tokenizer, and we'll mask the sixth token (index 5) the sequence. \n","\n","When using the `distilbert-base-cased` checkpoint to unmask that (sixth token, index 5) token, what is the most probable predicted token (please provide the decoded token, and not the ID)? \n","\n","Tips: \n","- You might find the transformers docs (https://huggingface.co/docs/transformers/index) useful. \n","- You might find the datasets docs (https://huggingface.co/docs/datasets/index) useful. \n","- You might also be interested in the Hugging Face course (https://huggingface.co/course/chapter1/1)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import DistilBertTokenizer, DistilBertForMaskedLM\n","import datasets\n","\n","tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")\n","model = DistilBertForMaskedLM.from_pretrained(\"distilbert-base-cased\")\n","\n","dataset = datasets.load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n","train_dataset = dataset[\"train\"]\n","\n","# Take the 11th example\n","example = train_dataset[10]\n","\n","# Tokenize the example\n","tokens = tokenizer.tokenize(example[\"text\"])\n","\n","# Mask the 6th token\n","tokens[5] = \"[MASK]\"\n","\n","# Convert the tokens to their IDs\n","input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","# Unmask the 6th token\n","outputs = model(input_ids)[0]\n","predicted_token = tokenizer.decode(torch.argmax(outputs[0, 5]).item())\n","\n","print(\"The most probable predicted token is:\", predicted_token)\n"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
