{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Transform the data so that it can be modeled, stating assumptions and simplifications as you go. What can you notice about the data ahead of the modeling process?_\n",
    "\n",
    "Before modeling the data, it needs to be transformed into a format that can be used by the model. This includes cleaning the data (removing missing values, outliers, etc.), converting categorical variables into numerical variables, and scaling numerical variables if necessary. Assumptions and simplifications that may need to be made include assuming that the data is missing at random, and simplifying complex relationships between variables into more manageable forms. The function `clean_dataset` was used below to remove infinite and complex numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_aptitude_exam</th>\n",
       "      <th>same_industry</th>\n",
       "      <th>unexcused_absences</th>\n",
       "      <th>hs_gpa</th>\n",
       "      <th>job_offered</th>\n",
       "      <th>good_behavior</th>\n",
       "      <th>high_school</th>\n",
       "      <th>enrolled_late</th>\n",
       "      <th>instructor</th>\n",
       "      <th>sensitive_01</th>\n",
       "      <th>...</th>\n",
       "      <th>sensitive_14</th>\n",
       "      <th>sensitive_15</th>\n",
       "      <th>sensitive_17</th>\n",
       "      <th>sensitive_18</th>\n",
       "      <th>sensitive_19</th>\n",
       "      <th>sensitive_20</th>\n",
       "      <th>sensitive_22</th>\n",
       "      <th>sensitive_23</th>\n",
       "      <th>sensitive_24</th>\n",
       "      <th>sensitive_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inst_9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.772</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>inst_5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.93832</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.740</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>inst_6</td>\n",
       "      <td>0.77</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.33660</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>inst_5</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.32674</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.837</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>inst_2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90079</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_aptitude_exam  same_industry  unexcused_absences  hs_gpa  job_offered  \\\n",
       "0               96.0              0                   1   2.255            1   \n",
       "1               88.0              0                   2   2.772            1   \n",
       "2               90.0              0                   0   3.740            1   \n",
       "3              122.0              0                   2   3.206            1   \n",
       "4               82.0              0                   1   2.837            1   \n",
       "\n",
       "   good_behavior  high_school  enrolled_late instructor  sensitive_01  ...  \\\n",
       "0            0.0            0              0     inst_9          0.25  ...   \n",
       "1            1.0            1              0     inst_5          0.36  ...   \n",
       "2            0.0            2              0     inst_6          0.77  ...   \n",
       "3            0.0            3              0     inst_5          0.39  ...   \n",
       "4            1.0            4              0     inst_2          0.85  ...   \n",
       "\n",
       "   sensitive_14  sensitive_15  sensitive_17  sensitive_18  sensitive_19  \\\n",
       "0      -0.68430             1             0             1          0.82   \n",
       "1      -3.93832             1             0             0          0.91   \n",
       "2      -1.33660             1             1             1         -0.88   \n",
       "3      -0.32674             0             1             1         -0.98   \n",
       "4       0.90079             1             0             0         -0.41   \n",
       "\n",
       "   sensitive_20  sensitive_22  sensitive_23  sensitive_24  sensitive_25  \n",
       "0             1             0          0.33             1          0.44  \n",
       "1             0             0         -0.35             0          0.83  \n",
       "2             1             0         -1.18             1         -0.82  \n",
       "3             1             0         -0.74             0         -0.63  \n",
       "4             0             1         -0.56             1          1.63  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "# load data\n",
    "df_train = pd.read_csv('br_takehome_exam_2022_training.csv')\n",
    "df_scoring = pd.read_csv('br_takehome_exam_2022_scoring.csv')\n",
    "\n",
    "# preview data\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_aptitude_exam       0\n",
       "same_industry           0\n",
       "unexcused_absences      0\n",
       "hs_gpa                 20\n",
       "job_offered             0\n",
       "good_behavior         100\n",
       "high_school             0\n",
       "enrolled_late           0\n",
       "instructor             50\n",
       "sensitive_01            0\n",
       "sensitive_02            0\n",
       "sensitive_03            0\n",
       "sensitive_04            0\n",
       "sensitive_05            0\n",
       "sensitive_06            0\n",
       "sensitive_07            0\n",
       "sensitive_08            0\n",
       "sensitive_09            0\n",
       "sensitive_10          595\n",
       "sensitive_11            0\n",
       "sensitive_12            0\n",
       "sensitive_13            0\n",
       "sensitive_14            0\n",
       "sensitive_15            0\n",
       "sensitive_17            0\n",
       "sensitive_18            0\n",
       "sensitive_19            0\n",
       "sensitive_20            0\n",
       "sensitive_22            0\n",
       "sensitive_23            0\n",
       "sensitive_24            0\n",
       "sensitive_25            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_aptitude_exam     0\n",
       "same_industry         0\n",
       "unexcused_absences    0\n",
       "hs_gpa                0\n",
       "job_offered           0\n",
       "good_behavior         0\n",
       "high_school           0\n",
       "enrolled_late         0\n",
       "instructor            0\n",
       "sensitive_01          0\n",
       "sensitive_02          0\n",
       "sensitive_03          0\n",
       "sensitive_04          0\n",
       "sensitive_05          0\n",
       "sensitive_06          0\n",
       "sensitive_07          0\n",
       "sensitive_08          0\n",
       "sensitive_09          0\n",
       "sensitive_10          0\n",
       "sensitive_11          0\n",
       "sensitive_12          0\n",
       "sensitive_13          0\n",
       "sensitive_14          0\n",
       "sensitive_15          0\n",
       "sensitive_17          0\n",
       "sensitive_18          0\n",
       "sensitive_19          0\n",
       "sensitive_20          0\n",
       "sensitive_22          0\n",
       "sensitive_23          0\n",
       "sensitive_24          0\n",
       "sensitive_25          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean dataset\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.fillna(0, inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep]#.astype(np.float64)\n",
    "\n",
    "df_train_clean = clean_dataset(df_train)\n",
    "\n",
    "# np.any(np.isnan(df_train.hs_gpa)) # True\n",
    "# np.any(np.isnan(df_train_clean.hs_gpa)) # False\n",
    "\n",
    "# np.all(np.isfinite(df_train.hs_gpa)) # False\n",
    "# np.all(np.isfinite(df_train_clean.hs_gpa)) # True\n",
    "\n",
    "# np.any(np.isfinite(df_train.hs_gpa)) # True\n",
    "# np.any(np.isfinite(df_train_clean.hs_gpa)) # True\n",
    "\n",
    "\n",
    "# np.isfinite(df_train.hs_gpa).sum() # 980 # 1000\n",
    "# np.isfinite(df_train_clean.hs_gpa).sum() # 344\n",
    "# df_train_clean.hs_gpa.count() # 344\n",
    "\n",
    "# np.isnan(df_train.hs_gpa).sum() # 20\n",
    "# np.isnan(df_train_clean.hs_gpa).sum() # 0\n",
    "\n",
    "# check for missing values\n",
    "df_train_clean.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_aptitude_exam        0\n",
       "same_industry            0\n",
       "unexcused_absences       0\n",
       "hs_gpa                  89\n",
       "good_behavior          479\n",
       "high_school              0\n",
       "enrolled_late            0\n",
       "instructor             238\n",
       "sensitive_01             0\n",
       "sensitive_02             0\n",
       "sensitive_03             0\n",
       "sensitive_04             0\n",
       "sensitive_05             0\n",
       "sensitive_06             0\n",
       "sensitive_07             0\n",
       "sensitive_08             0\n",
       "sensitive_09             0\n",
       "sensitive_10          2883\n",
       "sensitive_11             0\n",
       "sensitive_12             0\n",
       "sensitive_13             0\n",
       "sensitive_14             0\n",
       "sensitive_15             0\n",
       "sensitive_17             0\n",
       "sensitive_18             0\n",
       "sensitive_19             0\n",
       "sensitive_20             0\n",
       "sensitive_22             0\n",
       "sensitive_23             0\n",
       "sensitive_24             0\n",
       "sensitive_25             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df_scoring.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_aptitude_exam     0\n",
       "same_industry         0\n",
       "unexcused_absences    0\n",
       "hs_gpa                0\n",
       "good_behavior         0\n",
       "high_school           0\n",
       "enrolled_late         0\n",
       "instructor            0\n",
       "sensitive_01          0\n",
       "sensitive_02          0\n",
       "sensitive_03          0\n",
       "sensitive_04          0\n",
       "sensitive_05          0\n",
       "sensitive_06          0\n",
       "sensitive_07          0\n",
       "sensitive_08          0\n",
       "sensitive_09          0\n",
       "sensitive_10          0\n",
       "sensitive_11          0\n",
       "sensitive_12          0\n",
       "sensitive_13          0\n",
       "sensitive_14          0\n",
       "sensitive_15          0\n",
       "sensitive_17          0\n",
       "sensitive_18          0\n",
       "sensitive_19          0\n",
       "sensitive_20          0\n",
       "sensitive_22          0\n",
       "sensitive_23          0\n",
       "sensitive_24          0\n",
       "sensitive_25          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean scoring dataset\n",
    "df_scoring_clean = clean_dataset(df_scoring)\n",
    "\n",
    "# check for missing values\n",
    "df_scoring_clean.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Train 2 or 3 models, and compare them in terms of how well they fit the data. Are there advantages or disadvantages to the approaches you’ve taken?_\n",
    "\n",
    "Here, a logistic regression model and a decision tree were used. These models can then be compared in terms of how well they fit the data by measuring their accuracy, precision, recall, and other metrics. As shown below, `logreg_acc = 0.92` and `dt_acc = 0.8033`. Advantages of logistic regression include its simplicity and interpretability, while decision trees can handle non-linear relationships and handle large amounts of data well. Disadvantages of decision trees include their tendency to overfit the data, and their lack of interpretability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature columns\n",
    "feature_cols = ['hs_gpa', 'high_school', 'unexcused_absences']\n",
    "\n",
    "# scale features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "df_train_clean[feature_cols] = scaler.fit_transform(df_train_clean[feature_cols])\n",
    "df_scoring_clean[feature_cols] = scaler.transform(df_scoring_clean[feature_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X = df_train_clean[feature_cols]\n",
    "y = df_train_clean['job_offered']\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# train logistic regression model\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# train decision tree model\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.92\n",
      "Decision tree accuracy: 0.8033333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "# calculate accuracy of logistic regression model\n",
    "logreg_acc = logreg.score(X_test, y_test)\n",
    "\n",
    "# calculate accuracy of decision tree model\n",
    "dt_acc = dt.score(X_test, y_test)\n",
    "\n",
    "# compare model accuracy\n",
    "print(\"Logistic regression accuracy:\", logreg_acc)\n",
    "print(\"Decision tree accuracy:\", dt_acc)\n",
    "\n",
    "# overall model comparison\n",
    "logregmod = logreg.predict(X_test)\n",
    "print(classification_report(y_test, logregmod))\n",
    "print(confusion_matrix(y_test, logregmod))\n",
    "print(accuracy_score(y_test, logregmod))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Choose the best model you fit above and produce scores for every row the provided scoring set. Compare the distribution of population scores to the training sample mean and briefly discuss your findings. What do you observe about the two populations? How might you change your analysis if you had more time/resources in light of this?_\n",
    "\n",
    "After comparing the models, the best one can be chosen and used to produce scores for every row in the provided scoring set. These scores can then be used to estimate the probability of each individual in the population being offered a job. The distribution of these scores can be compared to the training sample mean, and any discrepancies can be investigated. If there were more time and resources, more data can be collected and additional models can be trained and compared to ensure the best possible performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.**\n",
    "_Let’s say a client comes to you and asks for “the effect of absences (one of the variables in the dataset) on being offered a job.” What are some ways you might go about providing that? How would you communicate uncertainty around the ‘effect size’?_\n",
    "\n",
    "\n",
    "To provide the effect of absences on being offered a job, one way would be to fit a logistic regression model with absences as an independent variable and job offer as the dependent variable. The coefficient of absences can be interpreted as the change in log-odds of being offered a job for a one-unit increase in absences. \n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix,accuracy_score\n",
    " \n",
    "    x = df['unexcused_absences']\n",
    "    y = df['job_offered']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "    logmodel = LogisticRegression()\n",
    "    logmodel.fit(x_train, y_train)\n",
    " \n",
    "    predictions = logmodel.predict(x_test)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    \n",
    "\n",
    "Another way would be to use methods such as propensity score matching or instrumental variables to control for potential confounding variables. Uncertainty around the effect size can be communicated by providing a confidence interval for the coefficient or by using a hypothesis testing framework to determine the statistical significance of the effect."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** \n",
    "_Let's say your client is interested in understanding the uncertainty of the predictions produced by your model at the individual level. As an example, your model might say that person i has probability of being offered a job 0.78. How do you calculate uncertainty on that quantity?_\n",
    "\n",
    "To calculate uncertainty on the probability of being offered a job, one approach would be to use a technique called bootstrapping. This involves resampling the training data multiple times, fitting the model to each resample, and recording the model's prediction for each individual. By calculating the standard deviation of the predicted probabilities across the resamples, we can obtain an estimate of the uncertainty of the model's predictions. A Bayesian approach can also be used to calculate the posterior probability distribution of the predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.**\n",
    "_Let’s say a domain expert thinks that the model is not performing well for a subset of the population (e.g. folks with a low GPA). How would you check to see if the model is performing well among subpopulations of your training data?_\n",
    "\n",
    "One way to check the performance of the model among subpopulations would be subgroup analysis or discrimination analysis. Subgroup analysis involves comparing the model's performance within specific subpopulations (e.g. low GPA) to its overall performance. Discrimination analysis involves calculating a measure of fairness (e.g. the difference in false positive rates between subpopulations) to check if the model is treating different subpopulations fairly. These analyses can help identify any potential bias or poor performance within specific subpopulations, and help us understand the reasons behind them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 02:22:02) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2f1dc8f986a4de63760f97c74a2a9047e76864767ebd41fc9dd619b409c5d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
